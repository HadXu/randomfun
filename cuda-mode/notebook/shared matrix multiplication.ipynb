{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a155624-595f-4ce6-96b8-ed8b0a8beaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,math,sys,torch,re,numpy as np\n",
    "from types import SimpleNamespace as ns\n",
    "from collections import namedtuple\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a316f56-83a4-42e0-856a-29ea6c156ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
    "dim3 = namedtuple('dim3', ['x','y','z'], defaults=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f5926db-e947-4b18-9ef4-c45c12477e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dim3(x=3, y=2, z=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim3(x=3, y=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f905891-14dd-421c-9e50-42d4579f8109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdc58298a70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.cpp_extension import load_inline\n",
    "\n",
    "cuda_begin = r'''\n",
    "#include <torch/extension.h>\n",
    "#include <stdio.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "#define CUDA_ERR(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
    "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
    "{\n",
    "   if (code != cudaSuccess) \n",
    "   {\n",
    "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
    "      if (abort) exit(code);\n",
    "   }\n",
    "}\n",
    "__host__ __device__ inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a+b-1)/b;}\n",
    "'''\n",
    "\n",
    "def load_cuda(cuda_src, cpp_src, funcs, opt=True, verbose=False, name=None):\n",
    "    \"Simple wrapper for torch.utils.cpp_extension.load_inline\"\n",
    "    if name is None: name = funcs[0]\n",
    "    flags = \"-O3 -Xptxas -O3 -Xcompiler -O3\" if opt else \"-O0 -Xptxas -O0 -Xcompiler -O0\"\n",
    "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
    "                       extra_cuda_cflags=[flags], verbose=verbose, name=name)\n",
    "\n",
    "def cdiv(a,b):\n",
    "    \"Int ceiling division of `a` over `b`\"\n",
    "    return (a+b-1)//b\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4840fa58-d552-4923-aad0-542de83cc050",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.rand(5120, 256)\n",
    "m2 = torch.rand(256,5120)\n",
    "\n",
    "m1s = m1[:4]\n",
    "m2s = m2[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34602054-3b54-47a2-86b6-7622f7109dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8823, 0.9150, 0.3829, 0.9593, 0.3904, 0.6009, 0.2566, 0.7936, 0.9408,\n",
       "        0.1332, 0.9346, 0.5936, 0.8694, 0.5677, 0.7411, 0.4294, 0.8854, 0.5739,\n",
       "        0.2666, 0.6274])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s.flatten()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a5b9a7-90bb-4b9a-9a8e-e1f35a8f3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_kernel2d(f, blocks, threads, *args):\n",
    "    for i0 in range(blocks.y):\n",
    "        for i1 in range(blocks.x):\n",
    "            for j0 in range(threads.y):\n",
    "                for j1 in range(threads.x): f(dim3(i1,i0), dim3(j1,j0), threads, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6caa83ad-f503-4c50-97e9-66c4dc4308b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_bk(blockIdx, threadIdx, blockDim, m, n, out, h, w, k):\n",
    "    r = blockIdx.y*blockDim.y + threadIdx.y\n",
    "    c = blockIdx.x*blockDim.x + threadIdx.x\n",
    "    \n",
    "    if (r>=h or c>=w): return\n",
    "    o = 0.\n",
    "    for i in range(k):\n",
    "        o += m[r*k+i] * n[i*w+c]\n",
    "    out[r*w+c] = o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8f87d86-96ea-435e-8093-74c3a45b5e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_2d(m, n):\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    assert k==k2, \"Size mismatch!\"\n",
    "    output = torch.zeros(h, w, dtype=m.dtype)\n",
    "    tpb = dim3(16,16)\n",
    "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
    "    blk_kernel2d(matmul_bk, blocks, tpb,\n",
    "                 m.flatten(), n.flatten(), output.flatten(), h, w, k)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eee31ec6-0d7b-48de-bcc7-5fd9a1b13452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(matmul_2d(m1s, m2s), m1s@m2s).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e54b47-122c-45a4-a0cf-92f280762ff1",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5fb0822-0263-4434-9820-4d08626ef9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "__global__ void matmul_k(float* m, float* n, float* out, int h, int w, int k) {\n",
    "    int r = blockIdx.y*blockDim.y + threadIdx.y;\n",
    "    int c = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (r>=h || c>=w) return;\n",
    "    float o = 0;\n",
    "    for (int i = 0; i< k; ++i) \n",
    "        o += m[r*k+i] * n[i*w+c];\n",
    "    out[r*w+c] = o;\n",
    "}\n",
    "\n",
    "torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {\n",
    "    CHECK_INPUT(m);\n",
    "    CHECK_INPUT(n);\n",
    "\n",
    "    int h = m.size(0);\n",
    "    int w = n.size(1);\n",
    "    int k = m.size(1);\n",
    "\n",
    "    TORCH_CHECK(k==n.size(0), \"Size mismatch\");\n",
    "\n",
    "    auto output = torch::zeros({h, w}, m.options());\n",
    "\n",
    "    dim3 tpb(16, 16);\n",
    "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
    "\n",
    "    matmul_k<<<blocks, tpb >>>( m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k );\n",
    "\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''\n",
    "\n",
    "fname = 'matmul'\n",
    "\n",
    "def get_sig(fname, src):\n",
    "    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n",
    "    return res[0]+';' if res else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38cae450-801b-4302-a5a2-7855fbd08453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch::Tensor matmul(torch::Tensor m, torch::Tensor n);'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_src = get_sig(fname, cuda_src)\n",
    "cpp_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b2b7662-08d0-49b6-a544-8159372284ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_cuda(cuda_src, cpp_src, [fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aba6b88-222b-4ae1-9b01-5b6135288a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1c,m2c = m1.contiguous().cuda(),m2.contiguous().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a45ba6-1419-496e-94bd-e71beee13bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5120, 5120])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.matmul(m1c,m2c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c158259d-6641-4f67-824a-ae9f544fa68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(module.matmul(m1c,m2c), m1c@m2c).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b28baaf-1261-437f-b811-90530dc7b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.97 ms ± 54.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "module.matmul(m1c,m2c)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a2508-9dfe-42ab-bcef-3c489f69b7c5",
   "metadata": {},
   "source": [
    "# Shared Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b203a10f-74fd-4dd0-8826-a33476b3acd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829,  ..., 0.2576, 0.3470, 0.0240],\n",
       "        [0.7797, 0.1519, 0.7513,  ..., 0.4078, 0.5411, 0.0410],\n",
       "        [0.6556, 0.1186, 0.1836,  ..., 0.7819, 0.6328, 0.0317],\n",
       "        [0.1782, 0.9942, 0.6911,  ..., 0.3092, 0.0702, 0.1836]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faec308-cff9-4692-ac82-73d50a1746a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01522ec9-0fbc-4c2d-9759-10085c3bbd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_kernel2d_shar(f, blocks, threads, sh_sz, *args, **kwargs):\n",
    "    for i0 in range(blocks.y):\n",
    "        for i1 in range(blocks.x):\n",
    "            shared = torch.zeros(sh_sz)\n",
    "            f(dim3(i1,i0), threads, shared, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e426067-4061-452a-9549-089212ff6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_tiled_bk(blockIdx, blockDim, shared, m, n, out, h, w, k, tw):\n",
    "    shar_sz = tw*tw\n",
    "    ms,ns = shared[:shar_sz],shared[shar_sz:]\n",
    "    for ph in range( cdiv(k, tw) ):\n",
    "        idx = ph * tw\n",
    "        for tr in range(blockDim.y):\n",
    "            for tc in range(blockDim.x):\n",
    "                r, c = blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n",
    "                ms[tr*tw+tc] = m[ tc+idx + r*k] if r<h and idx+tc<k else 0.\n",
    "                ns[tr*tw+tc] = n[(tr+idx)*w +c] if c<w and idx+tr<k else 0.\n",
    "\n",
    "        for tr in range(blockDim.y):\n",
    "            for tc in range(blockDim.x):\n",
    "                r,c = blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n",
    "                for i in range(tw):\n",
    "                    if r*w+c<len(out): out[r*w+c] += ms[tr*tw+i] * ns[tw*i+tc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "659ee731-1c1b-461b-bce7-7865fa5ea1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_2d(m, n, tw=16):\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    assert k==k2, \"Size mismatch!\"\n",
    "    output = torch.zeros(h, w, dtype=m.dtype)\n",
    "    tpb = dim3(tw,tw)\n",
    "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
    "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
    "                      m.flatten(), n.flatten(), output.flatten(),\n",
    "                      h, w, k, tw=tw)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98e6f920-f0b9-413e-ad53-dcbacd359c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 256]), torch.Size([256, 5120]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14623c69-f245-406d-bae0-2519bc72ab8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(matmul_2d(m1s, m2s, tw=16), m1s@m2s).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa50a3b8-0856-4b06-ac97-d6fa4cf20230",
   "metadata": {},
   "source": [
    "# Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2816538a-3cf1-4539-96e9-acd17aa8bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from threading import Barrier, Thread\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "242d116d-d526-46a9-8337-319700a65c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "20\n",
      "10\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "def g(x, sb):\n",
    "    print(x)\n",
    "    sb.wait()\n",
    "    print(-x)\n",
    "    sb.wait()\n",
    "    print(x*10)\n",
    "\n",
    "num = 3\n",
    "sb = Barrier(num)\n",
    "with ThreadPoolExecutor(num) as ex: list(ex.map(lambda i: g(i,sb), range(1,num+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46285fa8-faaf-4d26-ad29-3b05826b8f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_kernel2d_shar(f, blocks, tpb, sh_sz, *args, **kwargs):\n",
    "    for i0 in range(blocks.y):\n",
    "        for i1 in range(blocks.x):\n",
    "            shar = torch.zeros(sh_sz)\n",
    "            syncb = Barrier(tpb.y*tpb.x)\n",
    "            threads = [Thread(target=f, args=(dim3(i1,i0), dim3(p,o), tpb, shar, syncb, *args), kwargs=kwargs)\n",
    "                       for o in range(tpb.y) for p in range(tpb.x)]\n",
    "            for tr in threads: tr.start()\n",
    "            for tr in threads: tr.join()\n",
    "\n",
    "def matmul_tiled_bk(blockIdx, threadIdx, blockDim, shared, syncb, m, n, out, h, w, k, tw):\n",
    "    tc,tr = threadIdx.x,threadIdx.y\n",
    "    r = blockIdx.y*blockDim.y + tr\n",
    "    c = blockIdx.x*blockDim.x + tc\n",
    "\n",
    "    shar_sz = tw*tw\n",
    "    ms,ns = shared[:shar_sz],shared[shar_sz:]\n",
    "\n",
    "    p = 0.\n",
    "    for ph in range(cdiv(k,tw)):\n",
    "        ms[tr*tw+tc] = m[ tc + ph*tw + r*k] if r<h and (ph*tw+tc)<k else 0.\n",
    "        ns[tr*tw+tc] = n[(tr + ph*tw)*w +c] if c<w and (ph*tw+tr)<k else 0.\n",
    "        syncb.wait()\n",
    "        for i in range(tw): p += ms[tr*tw+i] * ns[tw*i+tc]\n",
    "        syncb.wait()\n",
    "\n",
    "    if (r<h and c<w): out[r*w + c] = p\n",
    "\n",
    "def matmul_2d(m, n, tw=16):\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    assert k==k2, \"Size mismatch!\"\n",
    "    output = torch.zeros(h, w, dtype=m.dtype)\n",
    "    tpb = dim3(tw,tw)\n",
    "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
    "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
    "                      m.flatten(), n.flatten(), output.flatten(),\n",
    "                      h, w, k, tw=tw)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69b31575-fd46-4c51-a4fd-02e14de8e53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(matmul_2d(m1s, m2s, tw=16), m1s@m2s).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1326c823-349a-4038-b7fe-ba91529be9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56.9767, 60.0248, 60.5974, 63.2288],\n",
       "        [58.5341, 63.8303, 59.8225, 64.5254],\n",
       "        [60.0873, 66.2759, 63.8680, 64.7840],\n",
       "        [61.4536, 61.2220, 61.5788, 66.0657]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s@m2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "536aa801-50ac-4309-845d-3c80b16797c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56.9767, 60.0248, 60.5974, 63.2288],\n",
       "        [58.5341, 63.8303, 59.8225, 64.5254],\n",
       "        [60.0873, 66.2759, 63.8680, 64.7840],\n",
       "        [61.4536, 61.2220, 61.5788, 66.0657]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul_2d(m1s, m2s, tw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8843dc-d6c8-4ad5-bfe9-5381abb7aa85",
   "metadata": {},
   "source": [
    "# CUDA dynamic shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015fad0-9c02-4445-8ab9-5a3763dd4499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3d54627-e038-4fdf-b228-c1822f6a3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k, int tw) {\n",
    "    int tc=threadIdx.x, tr=threadIdx.y;\n",
    "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
    "\n",
    "    extern __shared__ float ms[];\n",
    "    float *ns = &ms[tw*tw];\n",
    "\n",
    "    float p = 0.0f;\n",
    "    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n",
    "        int idx = ph*tw;\n",
    "        ms[tr*tw + tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
    "        ns[tr*tw + tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
    "        __syncthreads();\n",
    "        for (int i=0; i<tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc];\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (r<h && c<w) out[r*w + c] = p;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b17f804-c7be-45bd-8bbd-680762f9f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src += r'''\n",
    "torch::Tensor matmul_dyn(torch::Tensor m, torch::Tensor n) {\n",
    "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
    "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
    "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
    "    auto output = torch::zeros({h, w}, m.options());\n",
    "\n",
    "    /*\n",
    "    // Commented out section demonstrating basic idea of dynamic size calculation\n",
    "    cudaDeviceProp devProp;\n",
    "    CUDA_ERR(cudaGetDeviceProperties(&devProp, 0));\n",
    "    int maxThreads = devProp.maxThreadsPerBlock;\n",
    "    size_t requiredSize = static_cast<size_t>(maxThreads) * 2 * sizeof(float);\n",
    "    size_t size = min(devProp.sharedMemPerBlock, requiredSize);\n",
    "    int TW = std::sqrt(maxThreads);\n",
    "    */\n",
    "\n",
    "    // We just set size fixed for now\n",
    "    int TW = 16;\n",
    "    size_t size = TW*TW * 2 * sizeof(float);\n",
    "    dim3 tpb(TW,TW);\n",
    "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
    "    matmul_k<<<blocks,tpb,size>>>(\n",
    "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k, TW);\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cbea6f5f-2844-4949-adde-4c86b58b29e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch::Tensor matmul_dyn(torch::Tensor m, torch::Tensor n);'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'matmul_dyn'\n",
    "cpp_src = get_sig(fname, cuda_src)\n",
    "cpp_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b95a4ea8-0f85-4312-b582-df9d82568ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_cuda(cuda_src, cpp_src, [fname], opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1358a5f5-b12c-417e-8bdf-d13587366052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(module.matmul_dyn(m1c,m2c), m1c@m2c).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7798508-7da8-4ac7-a14b-dca63b1a3979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.65 ms ± 358 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "module.matmul_dyn(m1c,m2c)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85482bf1-a421-4f9a-9523-b713b2356a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "constexpr int tw = 16;\n",
    "\n",
    "__global__ void matmul_ks(float *m, float *n, float *out, int h, int w, int k) {\n",
    "    __shared__ float ms[tw][tw], ns[tw][tw];\n",
    "    int tc=threadIdx.x, tr=threadIdx.y;\n",
    "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
    "\n",
    "    float p=0.0f;\n",
    "    for (int ph=0; ph < cdiv(k,tw); ++ph) {\n",
    "        int idx = ph*tw;\n",
    "        ms[tr][tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
    "        ns[tr][tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
    "        __syncthreads();\n",
    "        for (int i=0; i<tw; ++i) p += ms[tr][i] * ns[i][tc];\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (r<h && c<w) out[r*w + c] = p;\n",
    "}\n",
    "\n",
    "torch::Tensor matmul_static(torch::Tensor m, torch::Tensor n) {\n",
    "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
    "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
    "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
    "    auto output = torch::zeros({h, w}, m.options());\n",
    "    dim3 tpb(tw,tw);\n",
    "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
    "    matmul_ks<<<blocks,tpb>>>(m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5b70eba-d8db-4f61-b982-8e718914cb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'matmul_static'\n",
    "cpp_src = get_sig(fname, cuda_src)\n",
    "module = load_cuda(cuda_src, cpp_src, [fname])\n",
    "torch.isclose(module.matmul_static(m1c,m2c), m1c@m2c).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "306b06ec-4fc4-46f4-9b93-fc10e27b7a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.74 ms ± 167 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "module.matmul_static(m1c,m2c)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384beb5c-55e3-4dda-a61f-f3b11326b56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
